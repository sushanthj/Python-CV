{"0": {
    "doc": "CV Edge Detection and Filters",
    "title": "CV Edge Detection and Filters",
    "content": "{: .text-delta } 1. TOC {:toc} # Before you Begin {: .fs-9 } [Youtube Lectures](https://www.youtube.com/playlist?list=PLmyoWnoyCKo8epWKGHAm4m_SyzoYhslk5){: .btn .fs-5 .mb-4 .mb-md-0 } [Reference Notes](https://www.crcv.ucf.edu/courses/cap5415-fall-2014/){: .btn .fs-5 .mb-4 .mb-md-0 } The terms convolution is used in a very loose manner and when people say convolution, they mostly mean correlation. However, in our code, we will follow strictly the definition of convolution by flipping the kernel accordingly. Note that if we have a symmetric kernel, then convolution and correlation would be the same Also, people include the aspects of filtering (i.e taking a kernel and running it over an image) in the overarching term 'Convolution'. # Basics ## Image - Kernel - Padding Relations ![](/images/padding_formula.png) ## Convultion refer: [Conv](http://www.songho.ca/dsp/convolution/convolution.html) refer: [Conv vs Cross Conv](https://glassboxmedicine.com/2019/07/26/convolution-vs-cross-correlation/) ## Averaging Filter Here we use a simple np.ones((3,3)) kernel and do convolution calculate the sum of all neighbouring pixels. After that, we divide the sum by 9 (as 9 elements in the kernel) ```python import numpy as np import matplotlib.pyplot as plt from PIL import Image, ImageOps def convolve2D(image, kernel, padding=0, strides=1): # Flipping kernel = np.flipud(np.fliplr(kernel)) # Gather Shapes of Kernel + Image + Padding xKernShape = kernel.shape[0] yKernShape = kernel.shape[1] xImgShape = image.shape[0] yImgShape = image.shape[1] # Shape of Output Convolution xOutput = int(((xImgShape - xKernShape + 2 * padding) / strides) + 1) yOutput = int(((yImgShape - yKernShape + 2 * padding) / strides) + 1) output = np.zeros((xOutput, yOutput)) # Apply Equal Padding to All Sides if padding != 0: imagePadded = np.pad(image, pad_width=padding) else: imagePadded = image # Iterate through image for y in range(image.shape[1]): # Exit Convolution if y > image.shape[1] - yKernShape: break # Only Convolve if y has gone down by the specified Strides if y % strides == 0: for x in range(image.shape[0]): # Go to next row once kernel is out of bounds if x > image.shape[0] - xKernShape: break try: # Only Convolve if x has moved by the specified Strides if x % strides == 0: mat_mul = (kernel * imagePadded[x: x + xKernShape, y: y + yKernShape]) output[x, y] = (mat_mul.sum()/9) except: break return output ``` Note that the image we pass is grayscale: 'np.mean(color_img, axis=2) Also, we are padding the image correctly so that the loop can start at image[0,0] and still not face any issues. Note that the * operator is a different form of multiplication than matmul. Try to understand how the loop works at the boundary conditions ## Sobel Edge detector - Here we apply two convolutions to get fx and fy. i.e. the kernels 1 and 2 are designed in such a way that they give the central difference along x-axis or y-axis. - This central difference is essential the derivative of the matrix in x and y directions - Finally we combine the two fx and fy matrices to get the final resultant matrix - This resultant matrix has only edges as seen in the picture below. - Optionally we can also add a threshold to this resultant matrix to keep some edges and discard others ![](/images/sobel_diag.png) ![](/images/B1.jpg) ![](/images/sobel_output.png) ```python import numpy as np import matplotlib.pyplot as plt from PIL import Image, ImageOps def Sobel2D(image, kernel1, kernel2, padding=0, strides=1): # Flipping kernel1 = np.flipud(np.fliplr(kernel1)) kernel2 = np.flipud(np.fliplr(kernel2)) # Gather Shapes of Kernel xKernShape = kernel1.shape[0] yKernShape = kernel1.shape[1] xImgShape = image.shape[0] yImgShape = image.shape[1] # Shape of Output Convolution xOutput = int(((xImgShape - xKernShape + 2 * padding) / strides) + 1) yOutput = int(((yImgShape - yKernShape + 2 * padding) / strides) + 1) output_x = np.zeros((xOutput, yOutput)) output_y = np.zeros((xOutput, yOutput)) # Apply Equal Padding to All Sides if padding != 0: imagePadded = np.pad(image, pad_width=padding) else: imagePadded = image # Iterate to get fx (kernel1 is designed to yield differential in row-wise manner, lookup the kernel) for y in range(image.shape[1]): # Exit Convolution if y > image.shape[1] - yKernShape: break # Only Convolve if y has gone down by the specified Strides if y % strides == 0: for x in range(image.shape[0]): # Go to next row once kernel is out of bounds if x > image.shape[0] - xKernShape: break try: # Only Convolve if x has moved by the specified Strides if x % strides == 0: mat_mul = (kernel1 * imagePadded[x: x + xKernShape, y: y + yKernShape]) output_x[x, y] = (mat_mul.sum()) except: break # Iterate to get fy (kernel2 is designed to yield differential in column-wise manner, lookup the kernel) for y in range(image.shape[1]): # Exit Convolution if y > image.shape[1] - yKernShape: break # Only Convolve if y has gone down by the specified Strides if y % strides == 0: for x in range(image.shape[0]): # Go to next row once kernel is out of bounds if x > image.shape[0] - xKernShape: break try: # Only Convolve if x has moved by the specified Strides if x % strides == 0: mat_mul = (kernel2 * imagePadded[x: x + xKernShape, y: y + yKernShape]) output_y[x, y] = (mat_mul.sum()) except: break #find the resultant vector's magnitude resultant_mag = np.sqrt(np.square(output_x) + np.square(output_y)) #Normalize output to be between 0 and 255 #resultant_mag *= 255/resultant_mag.max() return resultant_mag if __name__ == '__main__': color_img = np.array(Image.open('B1.jpg')) img = np.mean(color_img, axis=2) ker1 = np.array([[-1,-2,-1],[0,0,0],[1,2,1]]) ker2 = np.array([[-1,0,1],[-2,0,2],[-1,0,1]]) pad = 1 new_img = Sobel2D(img, ker1, ker2) plt.figure(figsize=(8,8)) plt.imshow(new_img, cmap=plt.get_cmap(\"gray\")) plt.show() ``` ## Gaussian Matrix To map the gaussian distribution onto a kernel, we'll use a function which generates gaussian numbers as a distribution ```python x, y = np.meshgrid(np.linspace(-1,1,3), np.linspace(-1,1,3)) print(x) print(y) dst = np.sqrt(x*x+y*y) #Intializing sigma and muu sigma = 1 muu = 0.000 #Calculating Gaussian array gauss = np.exp(-( (dst-muu)**2 / ( 2.0 * sigma**2 ) ) ) print(\"2D Gaussian array :\\n\") print(gauss) ``` Note here that x and y are two different matrices and are shown below in the following order: ``` x: [[-1. 0. 1.] [-1. 0. 1.] [-1. 0. 1.]] y: [[-1. -1. -1.] [ 0. 0. 0.] [ 1. 1. 1.]] ``` ![](/images/2D_gaussian.jpeg) ## Gaussian Filtering Using the above gaussian matrix (the final output) as the kernel we do convolutions on the image ```python from avg_kernel import convolve2D import numpy as np import matplotlib.pyplot as plt from PIL import Image, ImageOps def gaussian(sig): ker_size = (2*sig)+1 x, y = np.meshgrid(np.linspace(-(ker_size // 2),(ker_size // 2), ker_size), np.linspace(-(ker_size // 2),(ker_size // 2), ker_size)) dst = np.sqrt(x*x+y*y) #Intializing sigma and muu sigma = 1 muu = 0.000 #Calculating Gaussian array gauss = np.exp(-( (dst-muu)**2 / ( 2.0 * sigma**2 ) ) ) print(gauss) return gauss def convolve(image, kernel, padding=1, strides=1): # Flipping kernel = np.flipud(np.fliplr(kernel)) # Gather Shapes of Kernel + Image + Padding xKernShape = kernel.shape[0] yKernShape = kernel.shape[1] xImgShape = image.shape[0] yImgShape = image.shape[1] # Shape of Output Convolution xOutput = int(((xImgShape - xKernShape + 2 * padding) / strides) + 1) yOutput = int(((yImgShape - yKernShape + 2 * padding) / strides) + 1) output = np.zeros((xOutput, yOutput)) # Apply Equal Padding to All Sides if padding != 0: imagePadded = np.pad(image, pad_width=padding) else: imagePadded = image # Iterate through image for y in range(image.shape[1]): # Exit Convolution if y > image.shape[1] - yKernShape: break # Only Convolve if y has gone down by the specified Strides if y % strides == 0: for x in range(image.shape[0]): # Go to next row once kernel is out of bounds if x > image.shape[0] - xKernShape: break try: # Only Convolve if x has moved by the specified Strides if x % strides == 0: mat_mul = (kernel * imagePadded[x: x + xKernShape, y: y + yKernShape]) output[x, y] = (mat_mul.sum()) except: break return output if __name__ == '__main__': color_img = np.array(Image.open('B1.jpg')) img = np.mean(color_img, axis=2) ker = gaussian(1) pad = 1 new_img = convolve(img, ker) plt.figure(figsize=(8,8)) plt.imshow(new_img, cmap=plt.get_cmap(\"gray\")) plt.show() ``` The final smoothened image with a 3x3 kernel and SD = 1 is shown below: ![](/images/gauss_filter.png) ## Marr-Hildreth Edge Detector Method 1 - Find the Laplacian of Gaussian matrix - Convolve with image - Find zero crossings and evaluate the slope - Apply threshold to slope The first two steps are solved in below code ```python from avg_kernel import convolve2D import numpy as np import matplotlib.pyplot as plt from PIL import Image, ImageOps def lap_of_gauss(sig): ker_size = (2*sig)+1 x, y = np.meshgrid(np.linspace(-(ker_size // 2),(ker_size // 2), ker_size), np.linspace(-(ker_size // 2),(ker_size // 2), ker_size)) dst = np.sqrt(x*x+y*y) #Intializing sigma and muu muu = 0.000 #Calculating Gaussian array p3 = np.exp(-( (dst-muu)**2 / ( 2.0 * sig**2 ) ) ) print(p3) p2 = (2-((dst**2)/(sig**2))) p1 = -(1/(((2*3.14)**0.5)*(sig**3))) l_of_g = (p1*(p2*p3)) print(l_of_g) return l_of_g def convolve(image, kernel, padding=1, strides=1): # Flipping kernel = np.flipud(np.fliplr(kernel)) # Gather Shapes of Kernel + Image + Padding xKernShape = kernel.shape[0] yKernShape = kernel.shape[1] xImgShape = image.shape[0] yImgShape = image.shape[1] # Shape of Output Convolution xOutput = int(((xImgShape - xKernShape + 2 * padding) / strides) + 1) yOutput = int(((yImgShape - yKernShape + 2 * padding) / strides) + 1) conv_out = np.zeros((xOutput, yOutput)) # Apply Equal Padding to All Sides if padding != 0: imagePadded = np.pad(image, pad_width=padding) else: imagePadded = image # Iterate through image for y in range(image.shape[1]): # Exit Convolution if y > image.shape[1] - yKernShape: break # Only Convolve if y has gone down by the specified Strides if y % strides == 0: for x in range(image.shape[0]): # Go to next row once kernel is out of bounds if x > image.shape[0] - xKernShape: break try: # Only Convolve if x has moved by the specified Strides if x % strides == 0: mat_mul = (kernel * imagePadded[x: x + xKernShape, y: y + yKernShape]) conv_out[x, y] = (mat_mul.sum()) except: break return conv_out if __name__ == '__main__': color_img = np.array(Image.open('B1.jpg')) img = np.mean(color_img, axis=2) ker = lap_of_gauss(1) pad = 1 new_img = convolve(img, ker) plt.figure(figsize=(8,8)) plt.imshow(new_img, cmap=plt.get_cmap(\"gray\")) plt.show() ``` Method 2 - Find gaussian matrix - Convolve gaussian matrix with image - Find gradient(first derivative) and Double gradient(second derivative) in both x,y axes The below code shows how to find gradient using the 1D numpy.gradient() function ```python gradients = numpy.gradient(img) x_grad = gradients[0] y_grad = gradients[1] ``` ",
    "url": "/CV%20Concepts/",
    "relUrl": "/CV Concepts/"
  },"1": {
    "doc": "Dictionaries",
    "title": "Dictionaries",
    "content": "{: .text-delta } 1. TOC {:toc} # Some interesting examples on dictionaries ## Dict update and delete To update a dictionary and also delete some items in it, we may get a few errors if we do the following: ```python for a,b in word_dictionary_init.items(): if b >= 5: word_dictionary_init[a] = word_count word_count += 1 else: del word_dictionary_init[a] ``` Here values of a and b are messed up because we keep deleting the items. Therefore a better way to do in THIS CASE is as follows: ```python index = 0 for word_key in list(word_dict.keys()): if word_dict[word_key] >= 5: word_dict[word_key] = index index += 1 else: del word_dict[word_key] return word_dict ``` # Ordered Dictionaries In case we want a dictionary to also follow structure like a list, we use these dictionaries However, these dictionaries take up more space than normal dicts due to their doubly-linked lists backend. The process to create such a dict is shown below: ```python from collections import OrderedDict self.depth_dictionary = OrderedDict() # access the dictonary like any other dictionary: self.depth_dictionary['favourite_cake'] = 'pineapple' # however, to remove the first item in such a dict, we have simple functions like below: if len(self.depth_dictionary) > 10: self.depth_dictionary.popitem(last=False) # in the above line, if last=True, then it will delete the last item of the dict ``` ",
    "url": "/Dictionaries/",
    "relUrl": "/Dictionaries/"
  },"2": {
    "doc": "Exceptions and File Handling",
    "title": "Exceptions and File Handling",
    "content": "{: .text-delta } 1. TOC {:toc} # Intro - Accessing a non−existent dictionary key will raise a KeyError exception. - Searching a list for a non−existent value will raise a ValueError exception. - Calling a non−existent method will raise an AttributeError exception. - Referencing a non−existent variable will raise a NameError exception. - Mixing datatypes without coercion will raise a TypeError exception. # The 'else' part of try and except: ```python try: from EasyDialogs import AskPassword except ImportError: getpass = default_getpass else: getpass = AskPassword finally: pass ``` A try...except block can have an else clause, like an if statement. If no exception is raised during the try block, the else clause is executed afterwards. finally runs no matter what. In this case, that means that the from EasyDialogs import AskPassword import worked, so you should bind getpass to the AskPassword function. # Working with Files ## Opening Files When we use the __open__ bulit-in function to open a file, it creates a file object (like instantiating a file, but we don't get class instance, we just get a file) and we can open a file in different modes as well: ```python print open.__doc__ #displays all possible modes >>> f = open(\"/music/_singles/kairo.mp3\", \"rb\") >>> f >>> ``` ## Built-in File Methods f.tell() = outputs current position of pointer in file f.seek( #bytes to consider, start from start/current/end pos) = moves pointer according 2 arguments provided f.read(128) = reads 128 bytes from file and returns data as a string f.close = closes a file f.closed = returns boolean depending upon whether file open or not f.write('some string') = adds the string to the file wherever the current pointer is ```python >>> logfile = open('test.log', 'w') >>> logfile.write('test succeeded') >>> logfile.close() >>> print file('test.log').read() test succeeded ``` Note. file is a synonym for open. This one−liner opens the file, reads its contents, and prints them. ### The sys Module sys.modules is a dictionary containing all python modules which were imported since you started the IDE. As we know, each dictionary is a key value pair. So in this case, __key = module name, value = module object__ ```python >>> import sys >>> print '\\n'.join(sys.modules.keys()) win32api os.path os exceptions __main__ ntpath nt sys __builtin__ site signal UserDict ``` Passing a module name as an argument to the sys.modules will give its location: ```python from fileinfo import MP3FileInfo MP3FileInfo.__module__ >>>'fileinfo' sys.modules[MP3FileInfo.__module__] >>> ``` ### The os.path module Suppose we have a specific module to concatenate two strings, or we have a separate module to split a string. This module can be OS specific, and therefore we may not know the __exact name of the module__ In situations like this, we can make use of the os.path : ```python import os os.path.join(\"c:\\\\music\\\\ap\\\\\", \"mahadeva.mp3\") >>>'c:\\\\music\\\\ap\\\\mahadeva.mp3' (filepath, filename) = os.path.split(\"c:\\\\music\\\\ap\\\\mahadeva.mp3\") filepath >>>'c:\\\\music\\\\ap' os.listdir(\"c:\\\\music\\\\_singles\\\\\") >>>['a_time_long_forgotten_con.mp3', 'hellraiser.mp3', 'kairo.mp3', 'long_way_home1.mp3', 'sidewinder.mp3', 'spinning.mp3'] ``` The os.listdir takes the path of a directory and just lists out the contents Similarly there exists os.path.isfile(pathname), which outputs 1 if it is a file, or 0 if not. ```python >>> [f for f in os.listdir(dirname) if os.path.isdir(os.path.join(dirname, f))] ['cygwin', 'docbook', 'Documents and Settings'] ``` ",
    "url": "/Exceptions+File_Handlers/",
    "relUrl": "/Exceptions+File_Handlers/"
  },"3": {
    "doc": "File Ops and Parsing",
    "title": "File Ops and Parsing",
    "content": "{: .text-delta } 1. TOC {:toc} # Refer refer: [Conv](https://diveintopython3.net/files.html) # Built-in Functions: ## Open and close a file automatically In the following example we will use the file.read() and file.seek() functions: - file.seek(17) goes to the 17th byte of the file - file.read(1) reads 1 character from the file at the current position of the pointer ```python with open('examples/chinese.txt', encoding='utf-8') as a_file: a_file.seek(17) a_character = a_file.read(1) print(a_character) ``` ## To print one line at a time Note. {:>4} means that print line_number right justified within 4 spaces (see example below) Observe the with block of code ```python line_number = 0 with open('examples/favorite-people.txt', encoding='utf-8') as a_file: ① for a_line in a_file: ② line_number += 1 print('{:>4} {}'.format(line_number, a_line.rstrip())) ``` ",
    "url": "/File_Ops_and_Parsing/",
    "relUrl": "/File_Ops_and_Parsing/"
  },"4": {
    "doc": "Functions and Modules",
    "title": "Functions and Modules",
    "content": "{: .text-delta } 1. TOC {:toc} # Built-in Functions ## The str dir and callable Functions 1\\. str function str coerces data into a string. Every datatype can be coerced into a string ```python >>> horsemen = ['war', 'pestilence', 'famine'] >>> str(horsemen) \"['war', 'pestilence', 'famine', 'Powerbuilder']\" >>> str(None) 'None' >>> str(odbchelper) \"\" ``` 2\\. dir function This function returns a list of all possible methods in a list/dict/module ```python >>> li = [] >>> dir(li) ['append', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort'] >>> d = {} >>> dir(d) ['clear', 'copy', 'get', 'has_key', 'items', 'keys', 'setdefault', 'update', 'values'] >>> import odbchelper >>> dir(odbchelper) ['__builtins__', '__doc__', '__file__', '__name__', 'buildConnectionString'] ``` 3\\. callable funciton It takes any object as input and returs if the object can be called or returns if uncallable Let's take for example two built-in functions of the string module (these functions are now deprecated though) string.punctuation returns a string of possible characters to be used in a string. However, the function itself is not callable to be used elsewhere. ```python >>> string.punctuation '!\"#$%&\\'()*+,−./:;?@[\\\\]^_`{|}~' >>> callable(string.punctuation) False ``` Now lets try a new built-in function This function as we know can be called to join any two strings. Therefore: ```python >>> callable(string.join) True ``` All the above Built-in functions are present in a module called # Getting Object References with getattr The getattr function takes an input as a string, if that string referes to any method, then it returns that method itself Closely look and understand the following example code. Also, note how the method is referenced as a string \"pop\". Also, see how calling a list function like pop without the parenthesis does a similar job ```python >>> li = [\"Larry\", \"Curly\"] >>> li.pop >>> getattr(li, \"pop\") >>> getattr(li, \"append\")(\"Moe\") >>> li [\"Larry\", \"Curly\", \"Moe\"] >>> getattr({}, \"clear\") ``` In the last line we see that the getattr function inputs a blank dict, however it still works becuase python knows the datatype is dict and that we are also asking for a dict method \"clear\". Note if we don't know what clear will do, we can always say: ```python d = {} print(d.clear.__doc__) ``` The above code will output the doc string for clear ## getattr as a Dispatcher Let's assume that we have a module called which has three functions: output_html, output_xml, output_text Now let's have a main output program which takes statstout as an input. Here we see the power of the getattr function of accepting strings and relating them to module functions. Also, with this getattr, we may/may not define an attribute to statsout. ```python import statsout def output(data, format=\"text\"): output_function = getattr(statsout, \"output_%s\" % format, statsout.output_text) return output_function(data) ``` The return output_function statement runs the particular function in statstout based on the argument (data), which is in turn based on the argument given to def output(data, format=\"text\") Note that we give getattr a third argument, which works as the default value in case the second argument is unavailable ## input and map functions ```python points = list() for i in range(4): a = list(map(float, input().split())) points ``` __split__ is a string functions which splits the lines in a string. __map__ is an in-built function which uses two arguments: a function and an iterable(list or dict) ```python def addition(n): return n*2 numbers = {1:'one',2 : 'two', 3: 'three'} result = map(addition,numbers.values()) print(list(result)) >> ['oneone', 'twotwo', 'threethree'] ``` ## Typecasting and converting to list all while taking user input ```python a = list(map(float, input('enter value').split())) print(a) ``` ",
    "url": "/Power%20of%20Introspection/",
    "relUrl": "/Power of Introspection/"
  },"5": {
    "doc": "Git Concepts",
    "title": "Git Concepts",
    "content": "{: .text-delta } 1. TOC {:toc} # Before you Begin {: .fs-9 } [Reference](https://www.w3schools.com/git/git_getstarted.asp?remote=github){: .btn .fs-5 .mb-4 .mb-md-0} In the above link, follow the procedures, but instead of using username and password each time, setup the ssh keys and use them more often *ssh keys are found in ./.ssh folder (or lookup keygen to generate your keys)* # Basics of generating new content in local and pushing to github ## Process for adding to a github page git add . \\ git commit -m \"made new code\" \\ git push or git push origin develop (if you cloned from develop branch) ## If you want to track a different branch - git branch --set-upstream-to=origin/master \\ git add . \\ git push or make a new remote - git remote add ts_origin_wiki git@github.com:sjayanth21/BR_Wiki.git \\ git push --set-upstream ts_origin_wiki master \\ git push ts_origin_wiki_master ## Working with remotes Any folder can have a number of remotes like: origin and ts_origin_github To make local branch master track a different remote branch (branch in your cloud github repo) do: git branch --set-upstream-to=origin/master or git branch --set-upstream-to=origin/develop ## If you cloned a repo, forked your own branch (using git checkout) You may need to pull from upstream to update your codebase \\ However, running a simple 'git pull' may throw merge conflicts So do the following 1. Run a 'git fetch' to get the updates on all branches (and if any new branch has been added) 2. In your personal branch commit all changes by doing: git add, commit and push 3. sudo apt install meld 4. Now to get the upstream updates do 'git checkout develop' (whichever is the main branch) 5. Now to put this in your personal branch run 'git checkout feature/sj' 6. Now we do the actual merging using 'git merge develop' (this will merge everythin in deveop into the current branch viz feature/sj) 7. The above step would have thrown some merge conflicts, to solve that run 'git mergetool' 8. The above step opens meld, make all necessary resolutions and save 9. Now our codebase would have been updated to whatever we resolved in meld 10. Now run 'git commit' without any arguments as it is a 'merge commit' 11. Now as usual do 'git push origin feature/sj' to push your updated personal branch to github ## Points to Note - If you checkout a file 'git checkout blade.py' it resets the file to whatever is the latest from that branch in upstream - If you want to physically add or change remotes go to the respective folder and do 'nano .git/config' - the correct syntax for the merge command is: \\ 'git merge ts_origin/master' \\ What this does is that if the current branch is origin/develop it will merge the files of \\ current branch i.e origin/develop with ts_origin/master - Note that even if ts_origin/master is in ts_github account and origin/master is in sushanthj github account, it will still merge as long as remotes exist for both these accounts. If remotes don't exist, you can always add as shown up above ### Concepts for working with two repos or two repos on two different github accounts: Basically locally you will have 'master' branch if you do 'git branch' \\ This master can track two upstream branches using two different remotes \\ One remote is added automatically when you clone the repo \\ The next remote will have to be added manually to your other git account or other repo Then to push the same commit to both branches first do 'git push' \\ and see which repo it pushes to (say it pushes to origin/master \\ Then do 'git push --set-upstream ts_origin/develop' to push to your second repo \\ However, do note that your local branch always tracks to the latest branch you pushed to \\ i.e if you do a git pull, it will pull from the latest branch to which you pushed \\ in this case it will pull from ts_origin/develop ### Saving a patch file If you have changes made which you want to save locally and not push to remote, you can save a patch file ```bash git diff > new_changes.patch ``` Now to apply this patch onto any branch, do: ```bash git apply new_changes.patch ``` ### Saving changes by stashing Instead of saving a specific file for changes (such as a patch file), you could also stash your changes locally ``` git stash ``` The above command will stash all tracked changes. You could also stash only committed changes. Refer: [stashing](https://www.atlassian.com/git/tutorials/saving-changes/git-stash) To then apply the stashed changes (one time use only as pop will remove from stash) ``` git stash pop ``` To apply without popping do: ``` git stash apply ``` To remove any particular item in stash: ``` git stash drop ``` To view all entries in stash and then apply specific one do: ``` git stash list git stash apply n ``` n = stash item number ",
    "url": "/git_concepts",
    "relUrl": "/git_concepts"
  },"6": {
    "doc": "Intro",
    "title": "Intro",
    "content": "For Jekyll reference see [just_the_docs](https://pmarsceill.github.io/just-the-docs/) The following pages are built in order to understand Computer Vision and Machine Learning To deploy on heroku follow the steps in the link below (and use the gem files, rake files and proc files in this repo for reference) The following files will need to be copied from this repo: - config.ru - Rakefile - Procfile - static.json - config.yaml (only the differences) And only if necessary: - Gemfile - Gemfile.lock - remove _sites from .gitignore Run bundle exec jekyll serve after making the above changes After copying these files (or their necessary contents), install heroku cli and do: ```bash heroku login ``` Then do heroku create as per the below link and the other steps necessary (git push heroku master) [Deploy jekyll on heroku](https://blog.heroku.com/jekyll-on-heroku) Finally, go to heroku page -> settings -> change the name of the app and find the url ",
    "url": "/intro/",
    "relUrl": "/intro/"
  },"7": {
    "doc": "Lists and Strings",
    "title": "Lists and Strings",
    "content": "{: .text-delta } 1. TOC {:toc} # Lists and Strings ## Lists 1\\. Slicing of Lists (common across numpy arrays as well) ```python >>> li ['a', 'b', 'mpilgrim', 'z', 'example'] >>> li[:3] ['a', 'b', 'mpilgrim'] >>> li[3:] ['z', 'example'] >>> li[:] ['a', 'b', 'mpilgrim', 'z', 'example'] ``` If the left slice index is 0, you can leave it out, and 0 is implied. So li[:3] is the same as li[0:3] Similarly, if the right slice index is the length of the list, you can leave it out. So li[3:] is the same as li[3:5], because this list has five elements. Important Points to note - list has indeces starting from 0,1,2... - However len(string) and len(list) will give numbers counted as 1,2,3,4 - li[:2] outputs li[0] and li[1] - li[1:4] outputs li[1], li[2] and li[3] 2\\. Appending of Lists ```python >>> li ['a', 'b', 'mpilgrim', 'z', 'example'] >>> li.append(\"new\") >>> li ['a', 'b', 'mpilgrim', 'z', 'example', 'new'] >>> li.insert(2, \"new\") >>> li ['a', 'b', 'new', 'mpilgrim', 'z', 'example', 'new'] >>> li.extend([\"two\", \"elements\"]) >>> li ['a', 'b', 'new', 'mpilgrim', 'z', 'example', 'new', 'two', 'elements'] ``` Append adds a single element to the end of the list. Insert inserts a single element into a list at a specified location and the original placeholder at that index gets bumped to the next index Extend concatenates lists. 3\\. Removing Items ```python >>> li ['a', 'b', 'new', 'mpilgrim', 'z', 'example', 'new', 'two', 'elements'] >>> li.remove(\"z\") >>> li ['a', 'b', 'new', 'mpilgrim', 'example', 'new', 'two', 'elements'] >>> li.remove(\"new\") >>> li.pop() 'elements' >>> li ['a', 'b', 'mpilgrim', 'example', 'new', 'two'] ``` 4\\. List Operators ```python >>> li = ['a', 'b', 'mpilgrim'] >>> li = li + ['example', 'new'] >>> li ['a', 'b', 'mpilgrim', 'example', 'new'] >>> li += ['two'] >>> li ['a', 'b', 'mpilgrim', 'example', 'new', 'two'] >>> li = [1, 2] * 3 >>> li [1, 2, 1, 2, 1, 2] ``` 5\\. Assignment to Variables ```python >>> range(7) = [1, 2, 3, 4, 5, 6] (MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY, SUNDAY) = range(7) >>> MONDAY 0 ``` 6\\. Looping in Lists ```python >>> li = [1, 9, 8, 4] >>> [elem*2 for elem in li] [2, 18, 16, 8] >>> li [1, 9, 8, 4] ``` As we can see from the above, looping did not change the actual variables in the list, python uses a seperate list in memory to loop To make sense of this, look at it from right to left. li is the list you're mapping. Python loops through li one element at a time, temporarily assigning the value of each element to the variable elem. Python then applies the function elem*2 and appends that result to the returned list. ## Strings 1\\. Formatting for I/O ```python uid = \"sa\" >>> pwd = \"secret\" >>> print pwd + \" is not a good password for \" + uid secret is not a good password for sa print \"%s is not a good password for %s\" % (pwd, uid) secret is not a good password for sa >>> userCount = 6 >>> print \"Users connected: %d\" % (userCount, ) Users connected: 6 >>> print \"Users connected: \" + userCount Traceback (innermost last): File \"\", line 1, in ? TypeError: cannot concatenate 'str' and 'int' objects ``` Note here that (userCount,) is a tuple with one element. If we ask for only (userCount) python would throw an error 2\\. Looping over Dictionary elemetns ```python >>> params = {\"server\":\"mpilgrim\", \"database\":\"master\", \"uid\":\"sa\", \"pwd\":\"secret\"} >>> [k for k, v in params.items()] ['server', 'uid', 'database', 'pwd'] >>> [\"%s=%s\" % (k, v) for k, v in params.items()] ['server=mpilgrim', 'uid=sa', 'database=master', 'pwd=secret'] ``` 3\\. Joining String items in a dictionary with a secondary string You might have thought I meant that string variables are objects. But no, look closely at this example and you'll see that the string \";\" itself is an object, and you are calling its join method. The join method joins the elements of the list into a single string, with each element separated by a semi−colon. The delimiter doesn't need to be a semi−colon; it doesn't even need to be a single character. It can be any string. ```python >>> params = {\"server\":\"mpilgrim\", \"database\":\"master\", \"uid\":\"sa\", \"pwd\":\"secret\"} >>> \";\".join([\"%s=%s\" % (k, v) for k, v in params.items()]) 'server=mpilgrim;uid=sa;database=master;pwd=secret' ``` 4\\. Splitting a string Understand that split reverses join by splitting a string into a multi−element LIST. Note that the delimiter (\";\") is stripped out completely; it does not appear in any of the elements of the returned list. ```python >>> s 'server=mpilgrim;uid=sa;database=master;pwd=secret' >>> s.split(\";\") ['server=mpilgrim', 'uid=sa', 'database=master', 'pwd=secret'] >>> s.split(\";\", 1) ['server=mpilgrim', 'uid=sa;database=master;pwd=secret'] ``` Note that split can also take a secondary argument which controls the number of splits done on the string. # List Filetering In the below examples focus on the process of how we: Save -> each element in a list (by looping) -> if it satisfies some logic ```python >>> li = [\"a\", \"mpilgrim\", \"foo\", \"b\", \"c\", \"b\", \"d\", \"d\"] >>> [elem for elem in li if len(elem) > 1] ['mpilgrim', 'foo'] >>> [elem for elem in li if li.count(elem) == 1] ['a', 'mpilgrim', 'foo', 'c'] ``` count(list) is a list method to return the number of times a value occurs in a list. # Basic String and List Operations ## Finding Length of a String ```python name = \"sush\" print(len(name)) ``` ## Extracting characters from a string into a list ```python str1 = [char for char in name] ``` ## Substituting specific words of a string there exists a built-in function called re.sub which can do the following: ```python import re >>> s = '100 NORTH MAIN ROAD' >>> re.sub('ROAD$', 'RD.', s) '100 NORTH BROAD RD.' ``` The module __re__ means __'regular expression'__ Using the re.sub function, you search the string s for the regular expression 'ROAD$' and replace it with 'RD.'. This matches the ROAD at the end of the string s, but does not match the ROAD that's part of the word BROAD, because that's in the middle of s. However, a better way to do it would be to specify that ROAD should be a separate word on it's own. We can do this by adding a clause r\\bROAD$ which means that: Only if the raw string (r\\) has a word boundary around the word 'ROAD', only then sub: ```python '100 BROAD ROAD APT. 3' >>> re.sub(r'\\bROAD\\b', 'RD.', s) '100 BROAD RD. APT 3' ``` ## Looping over a list 'len' of list a = [a,b,c,d] gives output as 4. But there are only 3 indeces in our example list. Therefore we use a small trick to utilize the integer output given by len(list) ```python thislist = [\"apple\", \"banana\", \"cherry\"] for i in range(len(thislist)): print(thislist[i]) ``` ## Looping over the list of strings to access index and item values In the code below note that index comes first and then item value when we do enumerate. i.e. list(enumerate) => [(index1, item1), (index2, item2)] ```python for pos, letter in enumerate(str1): if letter in vowels: vowel_list.append(letter) vowel_index_list.append(pos) ``` Also remember that if we only say ```python list1 = ['B', 'F', 'F'] for i in list1: print(i) >>B >>F >>F ``` From above we can see that 'i' represents the actual item in the list and not it's index ## Accessing String Line-by-Line We use the `` method here but the arguement we pass is ```python for line in my_string.split('\\n'): print line ``` The above code will return the first line of the string However, we would need each line of a string seperately, Then we could use the code below: ```python txt = '''apple banana cherry orange''' x = txt.split('\\n') ``` # Small Note on Triangle loops ## Palindromes Palindromes like 1, 121, 12321, 1234321 are actually squares of multiples of 11. See this simple code below: ```python for i in range(1,int(input())+1): print (((10**i - 1)//9)**2) >>1 >>121 >>12321 >>....... ``` The operator serves as an exponential and the operator is used for floor division. i.e. 9//2 = 4 ## Recurring numbers Remember that any number divided by 9 (unless one of the number's factor is 9), throws recurrence i.e 10/9 = 1.1111111. Let's make use of this in code to get the following: ```python for i in range(1,int(input())): print(int(i * 10**i / 9)) >>1 22 333 4444 ``` ## print(*text) function The print of * for a text is equal as printing print(text[0], text[1], ..., text[n]) and this is printing each part with a space between. you can do: ```python text = 'PYTHON' for index in range(len(text)) print(\"\".join(list(text)[:index + 1])) ``` or you can just use the * operator as: ```python text = 'PYTHON' for index in range(len(text)) print(*text[:index + 1], sep='') ``` ",
    "url": "/Lists%20and%20Strings/",
    "relUrl": "/Lists and Strings/"
  },"8": {
    "doc": "Multi-Processing, JSONS, and User-Inputs",
    "title": "Multi-Processing, JSONS, and User-Inputs",
    "content": "{: .text-delta } 1. TOC {:toc} # Before you Begin {: .fs-9 } [Understand the Difference between Multi-Proc and Multi-Thread](https://www.geeksforgeeks.org/difference-between-multiprocessing-and-multithreading/){: .btn .fs-5 .mb-4 .mb-md-0 } # Understanding the Pool loop for Multi-Processsing Example code: ```python from multiprocessing import Pool from tqdm import tqdm #tqdm is used to show the progress bar, it's just a wrapper around a for loop as seen below #We define a random list annotations = [{'project_name':'1'}, {'project_name':'2'}] def print_images_labels(annotation): project_name = annotation[0] print(project_name) #process=10 means we used 10 CPU cores (usually CPU will have 8 cores and 16 threads owing to hyperthreading tech) pool = Pool(processes=10) argument_list = annotations result_list_tqdm = [] #by saying iterable=argumnet list, we ask it to loop over the annotations[] list for result in tqdm(pool.imap_unordered(func=print_images_labels, iterable=argument_list), total=len(argument_list)): result_list_tqdm.append(result) ``` In the above code we see that the module 'Pool' is what we use for multi-processing. There are other ways, you can explore later # Understanding JSON files A typical json file is shown below. It is just a list of dictionaries ```json { \"dataset\": [ { \"annotations\": [ { \"image_path\": \"images/Project_1098/Y0061712_5.JPG\", \"original_image_path\": \"Project_1098/Y0061712.JPG\", \"bbox_info\": [ { \"crop_coordinates\": [ 112, 1425, 856, 2169 ], \"box_coordinates\": [ 315, 332, 430, 413 ], \"box_attr\": { \"class\": \"cotton\", \"CottonWithDriedFoliage\": false, \"CottonWithRandomObject\": false, }, \"details\": { \"completion_date\": \"\", \"remarks\": \"\", \"project_id\": \"V2-M-DG-07-23-19-A20-T4-LB-WL-SC-ND-B7\", } } ] } ], \"dataset_details\": { \"version\": \"2.0.1\", \"creation_time\": \"2021-11-22 12:28:41.696893\" } } ] } ``` *Note that if a = [1,2,3,4] and b = {'1':1, '2':2} the method of accessing list and dict elements is a[1] or b['1']* \\ **i.e. both a[] and b[] use square brackets** # User Inputs using argparse This is a simple libraray which allows user to give arguments when running code along with some *tags* In the below example, we will see some tags such as: - '-j' is the tag the user has to type in while running the script followed by 1 space and it's required value \\ example '-j ./v2.0.2/trial.json' - '--json_loc' will be the identifier which argparse will return ```python import argparse def parse_args(): parser = argparse.ArgumentParser() parser.add_argument('-j', '--json_loc', default='./v2.0.1/dev_2.0.1.json', required=False, help='Path to json file') parser.add_argument('-ir', '--image_remove', required=False, default=None, nargs='*',help='Image Attributes which should not contribute to creating json') parser.add_argument('-br', '--box_remove', required=False, default=None, nargs='*', help='Box attributes which should not contribute to creating json') args = parser.parse_args() return args if __name__ == '__main__': args = parse_args() json_path = args.json_loc #image_remover_list is of type list image_remover_list = args.image_remove ``` Also observe that the 'ir' and 'br' tags have an extra argument called **nargs**, which modifies the type of user input In our case, user input '-ir CottonBlurred CottonShadow' will return a list = ['CottonBlurred', 'CottonShadow'] Furthermore, initialising json_path is like initialising any other variable ",
    "url": "/Multi-Proc,%20JSON,%20usr_inp/",
    "relUrl": "/Multi-Proc, JSON, usr_inp/"
  },"9": {
    "doc": "Numpy",
    "title": "Numpy",
    "content": "{: .text-delta } 1. TOC {:toc} # Before you Begin {: .fs-9 } [Official Documentation](http://scipy-lectures.org/intro/numpy/array_object.html#indexing-and-slicing){: .btn .fs-5 .mb-4 .mb-md-0 } Numpy and Scipy are two resources to compute a variety of functions on matrices. Scipy is built on top of numpy and has a larger codebase of modules which we can utilize ![](/images/numpy_axes.png) # Images and Arrays ## Image Operations ### Importing Images In the below code we input an image and convert it into an array. \\ Shape of an array is just it's size ```python im = array(Image.open('empire.jpg')) print im.shape, im.dtype ``` The output would look lik this: ```python (800, 569, 3) uint8 (RGB image) ``` ### Converting image to Greyscale This uses an extra library called Python Pillow ```python from PIL import Image, ImageOps im = array(Image.open('empire.jpg').convert('L'),'f') print im.shape, im.dtype ``` ### Plotting an image ```python img = np.array(Image.open('House2.jpg')) plt.figure(figsize=(8,8)) plt.imshow(img) plt.show ``` ## Array Functions and Operations ## Array Nomenclature ![](/images/3D_matrix_nomenclature.png) It's important to realise that we only care about shapes of a matrix and our computation revolves around the shape tuple (1,2,3) irrespective of which is row or column. Develop a generalized version of matrix definitions!! An image can have shape as (640,540,3). Here we need to think in the way that there are 640 rows and 540 columns and 3 RGB channels. Therefore, rows, columns, pages don't matter much. Just think in terms of shapes. ### sum() function in 1D ```python import numpy as np arr = [20, 2, .2, 10, 4] print(\"\\nSum of arr : \", np.sum(arr)) print(\"Sum of arr(uint8) : \", np.sum(arr, dtype = np.uint8)) print(\"Sum of arr(float32) : \", np.sum(arr, dtype = np.float32)) ``` Output: ```python Sum of arr : 36.2 Sum of arr(uint8) : 36 Sum of arr(float32) : 36.2 ``` In 1D it just computes the sum of all elements in the array. It can also do type conversion on the go. We can extend this same logic to 2D, there too it calculates the sum of all matrix elements ### sum() in 2D along axes Axis along which we want to calculate the sum value. Otherwise, it will consider arr to be flattened(works on all the axis). axis = 0 means it calculates sum of all elements in ith column and (i=1)th column.. axis = 1 means it calculates sum of all elements in (j)th column and (j+1)th column.. ```python arr = [[14, 17, 12, 33, 44], [15, 6, 27, 8, 19], [23, 2, 54, 1, 4,]] print(\"\\nSum of arr : \", np.sum(arr)) print(\"Sum of arr(axis = 0) : \", np.sum(arr, axis = 0)) print(\"Sum of arr(axis = 1) : \", np.sum(arr, axis = 1)) ``` Output would be: ```python Sum of arr : 279 Sum of arr(axis = 0) : [52 25 93 42 67] Sum of arr(axis = 1) : [120 75 84] ``` But notice how the vector of axis = 1 has been transposed to show as a row vector We change that behaviour by adding a second argument to the sum() function: ```python print(\"\\nSum of arr (keepdimension is True): \\n\", np.sum(arr, axis = 1, keepdims = True)) ``` Output ```python Sum of arr (keepdimension is True): [[120] [ 75] [ 84]] ``` ### Looping over an Image and Grayscale We can loop over individual elements in a matrix after knowing the shape of the matrix The shape of the image is given as a tuple eg. (640, 540, 3) - the last item of that tuple is the RGB spectrum (3 dimensions per pixel) - the first two items in the tuple is the actual size of the image ```python for i in range(img.shape[1]): print() ``` In the above code we are looping over the rows. Therefore we are looping 640 times. #### Method 1 : Consider this method of converting image into greyscale: ```python import numpy as np import matplotlib.pyplot as plt from PIL import Image, ImageOps img = np.array(Image.open('B1.jpg')) print(img.shape) for i in range(img.shape[0]): for j in range(img.shape[1]): grey_value = 0 for k in range(img.shape[2]): grey_value += img[i,j,k] img[i,j,0] = int(grey_value/3) img2 = img[:,:,1] plt.figure(figsize=(8,8)) plt.imshow(img2) plt.show() ``` Also note how we removed the third (extra) dimensions using: ``` img2 = img[:,:,1] ``` This method uses averaging to find grayscale. However a slightly modified version is usually preferred: #### Method 2: Accounting for Luminance Perception ```python import numpy as np import matplotlib.pyplot as plt from PIL import Image, ImageOps weight = [0.2989, 0.5870, 0.1140] img = np.array(Image.open('B1.jpg')) print(img.shape) for i in range(img.shape[0]): for j in range(img.shape[1]): grey_value = 0 for k in range(len(weight)): grey_value += (img[i,j,k]*weight[k]) img[i,j,0] = int(grey_value) img2 = img[:,:,1] plt.figure(figsize=(8,8)) plt.imshow(img2, cmap=plt.get_cmap(\"gray\")) plt.show() ``` #### Method 3: Simpler code using numpy.mean ```python from PIL import Image import numpy as np import matplotlib.pyplot as plt color_img = np.array(Image.open('B1.jpg')) / 255 img = np.mean(color_img, axis=2) plt.figure(figsize=(8,8)) plt.imshow(img, cmap=plt.get_cmap(\"gray\")) plt.show() ``` # Built-in Numpy functions ## Difference between dot, matmul, and * ![](/images/np.dot.png) ## Plotting a pixel-wise histogram ```python img = np.array(Image.open('emma_stone.jpg')) img_flat = img.flatten() plt.hist(img_flat, bins=200, range=[0, 256]) plt.title(\"Number of pixels in each intensity value\") plt.xlabel(\"Intensity\") plt.ylabel(\"Number of pixels\") plt.show() ``` ## Reshaping Arrays ```python x = np.arange(4).reshape((2,2)) x >>array([[0, 1], [2, 3]]) ``` ## Transpose of a matrix Simple transpose is done using the matrix.transpose() or matrix.T method (both are same). One of them is showed below: ```python # (refer matrix x in above example) np.transpose(x) array([[0, 2], [1, 3]]) ``` However the transpose function takes more arguments and this is important for 3D matrices. Note that if a 3D matrix say 'A' has shape (1,2,3), the result of transpose without specifying any extra argument will be (3,2,1) ``` x = np.ones((1, 2, 3)) np.transpose(x, (1, 0, 2)).shape >>(2, 1, 3) ``` Note. While declaring array as in np.ones(1,2,3). This can be interpreted in two ways: - If we are printing the array in terminal we will read it as: there are 1 pages, 2 rows and 3 columns - If it's an image, the shape will be 1 row, 2 coulmns and 3 will be for 3 RGB channels It's important to realise that we only care about shapes of a matrix and our computation revolves around the shape tuple (1,2,3) irrespective of which is row or column. Develop a generalized version of matrix definitions!! However, we will access each row/column starting from 0 as x[0,0,0] or x[1,1,1]. The second argument stands for the axes parameter. Axes are numbered as 0,1,2 i.e. default configuration of axes is (0,1,2) for a 3D array and (0,1) for a 2D array Therefore if we specify we're saying that we want the first two shapes interchanged. Remember that first two shapes are pages and rows. Hence, those two will interchange. ## Padding of Matrices Padding is used to ensure overall image size does not reduce while run filters/convulutions on it ```python import numpy as np x = np.ones(3) y = np.pad(x, pad_width=1) y # Expected result # array([0., 1., 1., 1., 0.]) ``` ## newaxis method ref: [newaxis](http://scipy-lectures.org/intro/numpy/array_object.html#indexing-and-slicing) This method can be used to convert a row vector to a column vector and at the same time add another dimension as shown below: ```python a = np.array([0,1,2]) print(a.shape) ``` Output: (3,) Now lets do the newaxis modification: ```python c = (a[:, np.newaxis]) print(c) print(c.shape) ``` Output: ```python [[0] [1] [2]] (3, 1) ``` Therefore we can see that the vector has been rotated and another dimension has been added to the shape tuple ## einsum Refer to this document: [einsum](https://ajcr.net/Basic-guide-to-einsum/) ## Stacking rows using vstack We can use this function to stack rows onto an exiting numpy array. ```python in_arr1 = geek.array([ 1, 2, 3] ) in_arr2 = geek.array([ 4, 5, 6] ) # Stacking the two arrays vertically out_arr = geek.vstack((in_arr1, in_arr2)) print (out_arr) ``` Practically we can use this in a specific case. If we don't know the number of rows we will be adding to a numpy array: - We will define the array as a 0 row array - We then add rows as we progress using the vstack function ```python word_array = np.array([]).reshape(0, maxlength) for message in messages: word_count = np.zeros((1, word_num)) for word in word_list: if word == \"yes\": word_count[0, word_dictionary[word]] += 1 word_array = np.vstack([word_array, word_count]) return word_array ``` ## Saving a numpy matrix in a text file ```python np.savetxt('./output/p06_sample_train_matrix', train_matrix[:100,:]) ``` ",
    "url": "/numpy/",
    "relUrl": "/numpy/"
  },"10": {
    "doc": "Objects",
    "title": "Objects",
    "content": "{: .text-delta } 1. TOC {:toc} # Difference between 'import module' and 'from module import' import module only pulls the module as an object and like any other object, it has only attributes ```python >>> import types >>> types.FunctionType >>> FunctionType NameError: There is no variable named 'FunctionType' ``` However, when we call Functiontype specifically, or if we do 'from types import *', the FunctionType gets added into the local namespace. Therefore we can do as below: ```python >>> from types import FunctionType >>> FunctionType ``` # Classes ## Note on __init__ __init__ methods are optional, but when you define one, you must remember to explicitly call the ancestor's __init__ method (if it defines one). This is more generally true: whenever a descendant wants to extend the behavior of the ancestor, the descendant method must explicitly call the ancestor method at the proper time, with the proper arguments. ## Class attributes Lets import a module 'fileinfo', and then lets create an instace of a class present within the module called 'FileInfo' ```python >>> import fileinfo >>> f = fileinfo.FileInfo(\"/music/_singles/kairo.mp3\") >>> f.__class__ >>> f.__doc__ 'store file metadata' ``` Every class instance has a built−in attribute, __class__, which is the object's class. Java programmers may be familiar with the Class class, which contains methods like getName and getSuperclass to get metadata information about an object. In Python, this kind of metadata is available directly on the object itself through attributes like __class__, __name__, and __bases__. if the variable f were to be in a loop, then the moment the loop ends, the instantiation of the class is also destroyed automatically. Therefore, python has a built-in protection against memory leaks ## Some terminology Let's take this base class as reference: ```python class UserDict: def __init__(self, dict=None): self.x = {} if dict is not None: self.update(dict) def somerand(self): pass ``` We know the role of the self.x variable here. But more formally it's called a \"data attribute\" as it is defined within the __init__ function of the class itself However, if we instantiate the class elsewhere and assign it to a variable eg. Then the resulting variable i.somerand() is called a __\"class attribute\"__ and depend on the particular instantiation of the class -> therefore, they aren't permanent like __data attributes__ Also note the above if statement doesn't have an indented block because only one statement is to be performed after logical evaluation. Therefore, it's basically just a shortcut representation ### Side Note on object identity and object equality In Java, you determine whether two string variables reference the same physical memory location by using str1 == str2. This is called object identity, and it is written in Python as str1 is str2. To compare string values in Java, you would use str1.equals(str2); in Python, you would use str1 == str2. # Examples on working with classes + built-in methods ```python import math class Complex(object): # Classes Dealing with Complex Numbers in python - Hacker Rank Solution START def __init__(self, real, imaginary): self.real = real self.imaginary = imaginary def __add__(self, no): real = self.real + no.real imaginary = self.imaginary + no.imaginary return Complex(real,imaginary) def __sub__(self, no): real = self.real - no.real imaginary = self.imaginary - no.imaginary return Complex(real,imaginary) def __mul__(self, no): real = self.real * no.real - self.imaginary * no.imaginary imaginary = self.real * no.imaginary + self.imaginary * no.real return Complex(real,imaginary) def __truediv__(self, no): x = float(no.real ** 2 + no.imaginary ** 2) y = self * Complex(no.real, -no.imaginary) real = y.real / x imaginary = y.imaginary / x return Complex(real, imaginary) def mod(self): real = math.sqrt(self.real ** 2 + self.imaginary ** 2) return Complex(real, 0) # Classes Dealing with Complex Numbers in python - Hacker Rank Solution END def __str__(self): if self.imaginary == 0: result = \"%.2f+0.00i\" % (self.real) elif self.real == 0: if self.imaginary >= 0: result = \"0.00+%.2fi\" % (self.imaginary) else: result = \"0.00-%.2fi\" % (abs(self.imaginary)) elif self.imaginary > 0: result = \"%.2f+%.2fi\" % (self.real, self.imaginary) else: result = \"%.2f-%.2fi\" % (self.real, abs(self.imaginary)) return result if __name__ == '__main__': c = map(float, input().split()) d = map(float, input().split()) x = Complex(*c) y = Complex(*d) print(*map(str, [x+y, x-y, x*y, x/y, x.mod(), y.mod()]), sep='\\n') ``` In the above code notice clearly how: - Built in functions are used and called (these functions don't have to be called outright, the `` operator or `` operator is called according to the built-in function) - The return from each function is saved in each individual class instance itself - We can call new class instances from within a class method itself (see the truediv function closely) ",
    "url": "/Objects/",
    "relUrl": "/Objects/"
  },"11": {
    "doc": "OpenCV",
    "title": "OpenCV",
    "content": "{: .text-delta } 1. TOC {:toc} # Before you Begin {: .fs-9 } [Reference](https://docs.opencv.org/master/d6/d00/tutorial_py_root.html){: .btn .fs-5 .mb-4 .mb-md-0 } Many numpy functions will still be used alongside OpenCV as it augments the capabilities of OpenCV ## Note: The axes convention for numpy and opencv are different in some instances For basic image ops: - numpy has [width, height, depth] as the three axes - opencv has [height, width, depth] as the three axes However, for operations such as cv2.rectangle, i.e. ```python image = cv2.rectangle(image, start_point, end_point, color, thickness) # the start point is (x,y) i.e. same as numpy ``` But, if we're extracting an ROI (see section below), then we do: ```ball = img[280:340, 330:390]``` here the 280:340 = height and 330:390 = width # Basic Image Operations ## Read Image, Overlap Image, Show Image and Create New Image ```python import numpy as np import cv2 as cv import matplotlib.pyplot as plt img = cv.imread('walk_1.jpg') img2 = cv.imread('walk_2.jpg') img3 = cv.add(img, img2) cv.imshow('img3', img3) cv.waitKey(0) cv.destroyAllWindows() cv2.imwrite(\"opencv-threshold-example.jpg\", img3) ``` ## Split RGB Channels ```python b,g,r = cv.split(img) img = cv.merge((b,g,r)) #or we can also use numpy and do faster/more efficiently than cv.split b = img[:,:,0] #to set all red pixels to zero img[:,:,2] = 0 ``` ## Extracting Region of Interest (ROI) The axes of an image by default is saved as: ```python h,w,d = img.shape() ``` In the above height, width, and depth: - depth is saved as it normally would be - height is defined as top of image is zero and bottom of image is max height / (opposite of the normal y-axis) - width is defined normally, from left to right like 'x-axis' ```python ball = img[280:340, 330:390] img[273:333, 100:160] = ball ``` ## Grayscale and Thresholding There are two common color spaces used in OpenCV\\ - cv.COLOR_BGR2GRAY - cv.COLOR_BGR2HSV Thresholding sSyntax is given as\\ cv.threshold(source, thresholdValue, maxVal, thresholdingTechnique) Few thresholding techniques are: - **cv.THRESH_BINARY**: If pixel intensity is greater than the set threshold, value set to 255, else set to 0 (black) - **cv.THRESH_BINARY_INV**: Inverted or Opposite case of cv.THRESH_BINARY - **cv.THRESH_TRUNC**: If pixel intensity value is greater than threshold, it is truncated to the threshold. The pixel values are set to be the same as the threshold. All other values remain the same - **cv.THRESH_TOZERO**: Pixel intensity is set to 0, for all the pixels intensity, less than the threshold value - **cv.THRESH_TOZERO_INV**: Inverted or Opposite case of cv.THRESH_TOZERO **The Thresholding will generate two outputs. That's why we'll save the output of cv.THRESH in two images** ```python # Make image grayscale before thresholding ALWAYS gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY) # Or make grayscale during image read itself gray_img = cv.imread(\"threshold.png\", cv.IMREAD_GRAYSCALE) # Apply Threshold ret, thresh1 = cv.threshold(grau_img, 120, 255, cv.THRESH_BINARY) cv.imshow('Binary Threshold', thresh1) ``` ## Adaptive Thresholding ( Also nice way to print multiple images) **Syntax : cv2.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C[, dst])** - src – Source 8-bit single-channel image. - dst – Destination image of the same size and the same type as src . - maxValue – Non-zero value assigned to the pixels for which the condition is satisfied. See the details below. - adaptiveMethod – Adaptive thresholding algorithm to use, ADAPTIVE_THRESH_MEAN_C or ADAPTIVE_THRESH_GAUSSIAN_C . See the details below. - thresholdType – Thresholding type that must be either THRESH_BINARY or THRESH_BINARY_INV . - blockSize – Size of a pixel neighborhood that is used to calculate a threshold value for the pixel: 3, 5, 7, and so on. - C – Constant subtracted from the mean or weighted mean (see the details below). Normally, it is positive but may be zero or negative as well. ```python import cv2 as cv import numpy as np from matplotlib import pyplot as plt img = cv.imread('sudoku.png',0) img = cv.medianBlur(img,5) ret,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY) th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,\\ cv.THRESH_BINARY,11,2) th3 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY,11,2) titles = ['Original Image', 'Global Thresholding (v = 127)', 'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding'] images = [img, th1, th2, th3] for i in range(4): plt.subplot(2,2,i+1),plt.imshow(images[i],'gray') plt.title(titles[i]) plt.xticks([]),plt.yticks([]) plt.show() ``` ______________________________________________________________________________________________ ## Creating custom window sizes and putting text on images The below code will also take user input and executes custom commands like an if-else statement ```python h1, w1, d1 = img.shape cv2.putText(img, img_orig_path, (20,20) , font, fontScale, fontColor, lineType) img = cv2.rectangle(img, (x1,y1), (x2,y2),(36,255,120), 3) cv2.namedWindow(\"display_image\",cv2.WINDOW_NORMAL) cv2.resizeWindow(\"display_image\",1000,1000) cv2.imshow(\"display_image\", img) k1 = cv2.waitKey(0) & 0xFF if k1 == ord('q'): cv2.destroyAllWindows() print(\"> User exit request\") break elif k1 == ord('p'): print('okay') else: pass ``` ## Bitwise operations ```python import numpy as np import cv2 as cv # Load two images img1 = cv.imread('messi5.jpg') img2 = cv.imread('opencv-logo-white.png') # I want to put logo on top-left corner, So I create a ROI rows,cols,channels = img2.shape roi = img1[0:rows, 0:cols] # Now create a mask of logo and create its inverse mask also img2gray = cv.cvtColor(img2,cv.COLOR_BGR2GRAY) ret, mask = cv.threshold(img2gray, 10, 255, cv.THRESH_BINARY) mask_inv = cv.bitwise_not(mask) # Now black-out the area of logo in ROI img1_bg = cv.bitwise_and(roi,roi,mask = mask_inv) # Take only region of logo from logo image. img2_fg = cv.bitwise_and(img2,img2,mask = mask) # Put logo in ROI and modify the main image dst = cv.add(img1_bg,img2_fg) img1[0:rows, 0:cols ] = dst cv.imshow('res',img1) cv.imshow('img1_bg', img1_bg) cv.imshow('img2_fg',img2_fg) cv.imshow('mask', mask) cv.imshow('mask_inv', mask_inv) cv.waitKey(0) cv.destroyAllWindows() ``` The output will be as follows: ![](/images/opencv1.png) ## Masking an Image - Firstly the mask has to be same size as image - Secondly, the mask needs a white region where we'll be performing our bitwise ops ```python # zero mask unwanted regions in the image mask = np.zeros([1200,1328], dtype=\"uint8\") mask = cv2.rectangle(mask,(130,300),(1200,1020),(255,255,255),-1) depth_img = cv2.bitwise_and(depth_img, depth_img, mask=mask) ``` ## Resizing an Image ```python #Default interpolation method is cv.INTER_LINEAR which is faster than cv.INTER_CUBIC img = cv.imread('messi5.jpg') res = cv.resize(img,None,fx=2, fy=2, interpolation = cv.INTER_CUBIC) ``` ## Translating and Rotating an Image **Syntax: cv2.warpAffine(src, M, dsize, dst, flags, borderMode, borderValue)** The parameter M is the transformation matrix and this matrix dictates whether we translate or rotate the image or any of the other several operations - src: input image - dst: output image that has the size dsize and the same type as src. - M: transformation matrix. - dsize: size of the output image. eg. cv.warpAffine((100,100)) - flags: combination of interpolation methods (see resize() ) and the optional flag - WARP_INVERSE_MAP that means that M is the inverse transformation (dst->src). - borderMode: pixel extrapolation method; when borderMode=BORDER_TRANSPARENT, it means that the pixels in the destination image corresponding to the “outliers” in the source image are not modified by the function. - borderValue: value used in case of a constant border; by default, it is 0. ### Translation The below example shows x_translation of 150 pixels and y_translation of 50 pixels ```python img = cv.imread('messi5.jpg',0) rows,cols = img.shape M = np.float32([[1,0,100],[0,1,50]]) dst = cv.warpAffine(img,M,(cols,rows)) cv.imshow('img',dst) cv.waitKey(0) cv.destroyAllWindows() ``` ### Rotation For rotation we manually find the correct rotation matrix using an inbuilt function of OpenCV ![](/images/opencv2.png) ```python img = cv.imread('messi5.jpg',0) rows,cols = img.shape # cols-1 and rows-1 are the coordinate limits. M = cv.getRotationMatrix2D(((cols-1)/2.0,(rows-1)/2.0),90,1) dst = cv.warpAffine(img,M,(cols,rows)) ``` ## Affine Transformation vs Perspective Transformation In Affine transformation all parallel liles will remain parallel after transformation. This also needs 3 points to be mapped from input to output as a reference to build the transformation matrix ```python img = cv.imread('drawing.png') rows,cols,ch = img.shape pts1 = np.float32([[50,50],[200,50],[50,200]]) pts2 = np.float32([[10,100],[200,50],[100,250]]) M = cv.getAffineTransform(pts1,pts2) dst = cv.warpAffine(img,M,(cols,rows)) ``` In Perspective transformation all straight lines will remain straight even after transformation This needs 4 point mapping from input to output image to build transformation matrix ```python import numpy as np import cv2 as cv img = cv.imread('sudoku.png') rows,cols,ch = img.shape pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]]) pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]]) M = cv.getPerspectiveTransform(pts1,pts2) dst = cv.warpPerspective(img,M,(300,300)) ``` ______________________________________________________________________________________________________ # Kernel Operations ## Averaging filter ```python import numpy as np import cv2 as cv from matplotlib import pyplot as plt img = cv.imread('opencv_logo.png') kernel = np.ones((5,5),np.float32)/25 dst = cv.filter2D(img,-1,kernel) plt.subplot(121),plt.imshow(img),plt.title('Original') plt.xticks([]), plt.yticks([]) plt.subplot(122),plt.imshow(dst),plt.title('Averaging') plt.xticks([]), plt.yticks([]) plt.show() ``` ## Gaussian Blur ```python img = cv.imread('opencv-logo-white.png') img1 = cv.blur(img,(5,5)) #Normal averging filter img2 = cv.GaussianBlur(img,(5,5)) ``` ## Perspective Transforms and Homography In homography we can: 1. Match the FOV of one camera to another camera (which is slighly offset from the first) 2. Warp an image to remove distorion effects We achieve this by first finding a homography matrix. The basic backend is shown below: ![](/images/homography.png) The basic code to find the homography matrix and to do the actual perspective transform uses three OpenCV functions: - ```cv2.findHomography(pts_dst, pts_src)``` - ```cv2.warpPerspective(im_dst, h, (im_src.shape[1],im_src.shape[0]))``` - ```transformed_points = cv2.perspectiveTransform(test_points,h)``` In the above options: h = transformation matrix \\ im_dst = destination image \\ im_src = source image \\ pts_dst = keypoints on the destination image \\ pts_src = keypoints on the source image **The destination image will be the image which will be transformed to match the source image** ```python from cgi import test import os import cv2 import numpy as np from datetime import datetime from numpy.lib.npyio import load def compute_transformation(src_path, dst_path, out_path=\"/home/sush/TS/misc/test_scripts/\"): # Read source image. im_src = cv2.imread(src_path) # Four corners of the book in source image # pts_idx = [1,2,3,4,5,6,13,7,8,9,10,11,12] pts_src = np.array([[24,240],[120,223],[252,224],[413,221],[315,332],[367,413],[438,467],[440,410],[365,474],[36,429],[36,499],[27,381]]) # Read destination image. im_dst = cv2.imread(dst_path) # Four corners of the book in destination image. pts_dst = np.array([[5,129],[115,107],[261,110],[436,106],[327,285],[382,418],[465,516],[465,418],[382,515],[19,438],[12,551],[10,352]]) # Calculate Homography h, status = cv2.findHomography(pts_dst, pts_src) #h, status = cv2.getPerspectiveTransform(pts_dst, pts_src) test_points = np.array([[328,218],[423,333]]) test_points = np.float32(test_points).reshape(-1,1,2) # Warp destination image to source image based on homography im_out = cv2.warpPerspective(im_dst, h, (im_src.shape[1],im_src.shape[0])) transformed_points = cv2.perspectiveTransform(test_points,h) print(\"transfored points are \\n\",transformed_points) # Display images cv2.imshow(\"Source Image\", im_src) cv2.imshow(\"Destination Image\", im_dst) cv2.imshow(\"Warped Source Image\", im_out) #cv2.imwrite(out_path + \"warped_img_{}_pts.png\".format(pts_src.shape[0]), im_out) np.savetxt(out_path + \"trans_matrix_{}_pts.txt\".format(pts_src.shape[0]),h, fmt='%s') print(\"h : \", h) cv2.waitKey(0) if __name__ == '__main__' : dst_path = \"/home/sush/TS/depth_testing/validation/camtop_raw/0.png\" src_path = \"/home/sush/TS/depth_testing/validation/depth_raw/0.png\" compute_transformation(src_path,dst_path) ``` ### Points to Note on perspective transform opencv functions: 1. cv2.warpPerspective is used to transform the whole image and takes ~50ms on a Xavier NX (as of 2022). Therefore it must be used sparingly to prevent the pipeline from slowing down and the ros_node from publishing at the low frequency 2. cv2.perspectiveTransform works only on points in the image (image vectors), and is therefore much faster *if the requirement is to map object detection boxes in one image onto another, then simply take the box corners and use perspectiveTransform to save computation time* # Buiding and Using opencv with CUDA ## The process for building opencv with CUDA ``` To build opencv from source do the following: ________________________________________________________ Install Dependencies sudo apt-get update sudo apt-get upgrade sudo apt-get install build-essential cmake unzip pkg-config sudo apt-get install libjpeg-dev libpng-dev libtiff-dev sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev sudo apt-get install libv4l-dev libxvidcore-dev libx264-dev sudo apt-get install libgtk-3-dev sudo apt-get install libblas-dev liblapack-dev gfortran sudo apt-get install python3-dev _______________________________________________________________________________________________________________________________ Pull the repos of Opencv and Opencv_contrib cd ~ wget -O opencv-4.5.1.zip https://github.com/opencv/opencv/archive/4.5.1.zip unzip -q opencv-4.5.1.zip mv opencv-4.5.1 opencv rm -f opencv-4.5.1.zip wget -O opencv_contrib-4.5.1.zip https://github.com/opencv/opencv_contrib/archive/4.5.1.zip unzip -q opencv_contrib-4.5.1.zip mv opencv_contrib-4.5.1 opencv_contrib rm -f opencv_contrib-4.5.1.zip _______________________________________________________________________________________________________________________________ If you want to work within a venv, create one and do a pip3 install numpy and pip install numpy Else, just do the same in global _______________________________________________________________________________________________________________________________ Go into the folder cd ~/opencv mkdir build cd build Then, run the below cmake command with all arguments (directly copy paste from here) cmake \\ -D CMAKE_BUILD_TYPE=RELEASE \\ -D CMAKE_INSTALL_PREFIX=/usr/local \\ -D INSTALL_PYTHON_EXAMPLES=OFF \\ -D INSTALL_C_EXAMPLES=OFF \\ -D OPENCV_ENABLE_NONFREE=ON \\ -D OPENCV_EXTRA_MODULES_PATH=~/opencv_contrib/modules \\ -D BUILD_EXAMPLES=ON \\ -D WITH_CUDA=ON \\ -D WITH_CUDNN=ON \\ -D OPENCV_DNN_CUDA=ON \\ -D WITH_CUBLAS=ON \\ -D CUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-10.2 \\ -D WITH_OPENGL=ON \\ -D INSTALL_C_EXAMPLES=OFF \\ .. ______________________________________________________________________________________________________________________________ Follow this up with: make sudo make install sudo ldconfig Now we need to link this new opencv to python: sudo /bin/bash -c 'echo \"/usr/local/lib\" >> /etc/ld.so.conf.d/opencv.conf' ________________________________________________________________________________________________________________________________ ``` References: [build reference](https://gist.github.com/raulqf/f42c718a658cddc16f9df07ecc627be7) [learnopencv.com/opencv-dnn-with-gpu-support](https://learnopencv.com/opencv-dnn-with-gpu-support/) [docs.opencv.org/4.x/d6/d15/tutorial_building_tegra_cuda](https://docs.opencv.org/4.x/d6/d15/tutorial_building_tegra_cuda.html) Use the below link to understand how we can use cuda for generic opencv functions [medium.com/dropout-analytics/opencv-cuda-for-videos](https://medium.com/dropout-analytics/opencv-cuda-for-videos-f3dcf346e398) [Opencv documentation for cuda](https://docs.opencv.org/4.5.1/d1/d1e/group__cuda.html) ## Example of cv2.cuda ```python start = time.time() # create an instance of the GpuMat object gpu_frame = cv2.cuda_GpuMat() # upload the image to the GPU via the api gpu_frame.upload(image_raw) h, w, c = image_raw.shape # notice how we are adding just cuda to make it work on GPU image = cv2.cuda.cvtColor(gpu_frame, cv2.COLOR_BGR2RGB) # Calculate width and height and paddings r_w = INPUT_W / w r_h = INPUT_H / h if r_h > r_w: tw = INPUT_W th = int(r_w * h) tx1 = tx2 = 0 ty1 = int((INPUT_H - th) / 2) ty2 = INPUT_H - th - ty1 else: tw = int(r_h * w) th = INPUT_H tx1 = int((INPUT_W - tw) / 2) tx2 = INPUT_W - tw - tx1 ty1 = ty2 = 0 # Resize the image with long side while maintaining ratio image = cv2.cuda.resize(image, (tw,th)) # Pad the short side with (128,128,128) image = image.download() image = cv2.copyMakeBorder( image, ty1, ty2, tx1, tx2, cv2.BORDER_CONSTANT, (128, 128, 128) ) ``` ",
    "url": "/OpenCV/",
    "relUrl": "/OpenCV/"
  },"12": {
    "doc": "Pandas Case Study",
    "title": "Pandas Case Study",
    "content": "{: .text-delta } 1. TOC {:toc} # Before you Begin {: .fs-9 } [Reference](){: .btn .fs-5 .mb-4 .mb-md-0} # Problem definition Few ROS nodes were profiled to measure the transfer delays between ROS nodes in series. I wrote the outputs from each node into a text file; indexing each entry with the camera_id of that particular image Now I had multiple text files, with entries like: ``` camID 9550 CD_in_time 1648216864996326208 camID 9551 CD_in_time 1648216865085628986 ``` The above lines were for one node only (the input to one node). Now, to process such data from all nodes, I had to convert these rows into a **pandas dataframe** # Solution Implementation ## Reading from a text file: We will be reading from a folder and extracting all text files from there. ```python from collections import defaultdict from copy import copy, deepcopy from operator import index import pandas as pd import csv import os import copy import glob from scipy.misc import electrocardiogram my_dir_path = \"/home/sush/TS/e2e_test/eval_sj\" collated_data = defaultdict(list) file_count = 0 for file in sorted(glob.glob(os.path.join(my_dir_path, '*.txt'))): file_count += 1 with open(file, \"r\") as file_open: for line in file_open: # add the contents of each line to a list elements = line.split(\"\\n\")[0].split('camID ')[1].split(\" \") # save data according to camID (which is the element[0] in each line) collated_data[elements[0]].append(elements[1]) collated_data[elements[0]].append((float(elements[2])*1000)) # Note. If the data for each index (here camID) does not match the lenght of data in other datapoints, # pandas cannot create a dataframe collated_data_clone = copy.deepcopy(collated_data) for cam_id, values in collated_data_clone.items(): # check if any entry (whose key is camID) is not recoreded in each node if len(values) < (file_count * 2): # if data missing in any node: delete the data for that particular camID del collated_data[cam_id] dframe = pd.DataFrame.from_dict(collated_data) # the above created df will have camID as columns, we want it to be row-wise therefore transpose dframe = dframe.transpose() # sort the columns according to name proc_time_column_no = 0 handover_column_no = 1 print(\"text file count is\", file_count) for i in range(int(file_count/2)): if i < file_count-1: proc_time_column_no += 4 handover_column_no += 4 dframe.insert(proc_time_column_no, 'proc_time_' + str(i), None) dframe.insert(handover_column_no, 'handover_' + str(i), None) else: proc_time_column_no += 4 dframe.insert(proc_time_column_no, 'proc_time_' + str(i), None) #print(dframe) for i in range(int(file_count/2)): time_columns = [((i+1)*4)-1, ((i+1)*4)-3] preproc_column_name = \"proc_time_\" + str(i) dframe[preproc_column_name] = dframe[time_columns[0]] - dframe[time_columns[1]] #print(dframe) dframe.to_csv(os.path.join(my_dir_path, 'evaluation.csv')) ``` ",
    "url": "/padas_case_study",
    "relUrl": "/padas_case_study"
  },"13": {
    "doc": "RegEx",
    "title": "RegEx",
    "content": "{: .text-delta } 1. TOC {:toc} # Before you Begin The regex functions mostly work with string inputs and basically do pattern matching. each expressions in a regex pattern is meant to match a specific part of a string Here are the most important ones you'll be learning: - \\d = matches digits from 0-9 - \\D = matches non-digits - \\s = matches whitespace - \\w = matches word characters - ^ = matches beginning of line - $ = matches end of line - [..] = matches whatever chars we specify in the brackets - [^..] = matches all characters other than those mentioned in brackets - (\\d{n}) = matches exactly n number of digits Also, we can do the following to match letters and numbers only: ```python pattern = r\"([a-zA-Z0-9])\\1+\" m = re.search(pattern,input()) if m: print(m.group(1)) else: print(-1) ``` In the above program we are finding the first occurence of an alphanumeric in an input string # Regex In the code above, we saw that some in-built functions of the re class were used. Let's list them out with basic descriptions: - re.search() = returns an object if a particular match is made for a pattern, we can then group this into a list using the re.group() function - re.split() = similar to split function of string, but returns a list in this case - re.sub() = replaces one or more matches with a string - re.findall() = returns a list containing all matches - re.group() = groups found objects (like the return type of re.search) into a list - re.complie() = see example below (it also returns an object on which we will have to do another .search to get callable objects) - re.match() = takes two arguments, i.e. the pattern to match and the string and returns a callable object which we can then group into a list if required ## Mundane patterns and re.search() Let's define a pattern which we want to use as a baseline for comparison: __Eg. pattern = '^M?M?M?$'__ Each symbol in the string pattern has a particular meaning: - __^__ = start looking for the pattern only if that pattern exists in the beginning of the string. If this didn't exist, then pattern can be found at any position of the string and it will return true - __M?__ = to optionally match at least a single __M__ character if avialable. However, since our string pattern has 3 such cases of __M?__, we will be matching anywhere between 1 and 3 chars - __$__ is the antagonistic counterpart to the __^__. The dollar sign means to say that match should happen right uptill the end of the string. - When we couple both __^__ and __$__, it means that the pattern should match exactly between start and end of string (i.e entire string should get matched), with no chars before or after the __M__'s ```python >>> import re >>> pattern = '^M?M?M?$' >>> re.search(pattern, 'MMM') >>> re.search(pattern, 'MMMM') #(No output here because $ insists that there should be no char after the third M, however there is another) ``` Note. Even two chars 'MM' would have been identified by our pattern as it would just ignore the third M as it's optional Interstingly, evne an empty string would have matched our pattern as ## n to m form ```python >>> pattern = '^M{0,3}$' >>> re.search(pattern, 'M') ``` This pattern says: \"Match the start of the string, then anywhere from zero to three M characters, then the end of the string.\" The 0 and 3 can be any numbers; if you want to match at least one but no more than three M characters, you could say M{1,3}. ## Verbose REGEX ```python pattern = \"\"\" ^ # beginning of string M{0,4} # thousands − 0 to 4 M's (CM|CD|D?C{0,3}) # hundreds − 900 (CM), 400 (CD), 0−300 (0 to 3 C's), or 500−800 (D, followed by 0 to 3 C's) (XC|XL|L?X{0,3}) # ones − 9 (IX), 4 (IV), 0−3 (0 to 3 I's), or 5−8 (V, followed by 0 to 3 I's) (IX|IV|V?I{0,3}) $ # end of string \"\"\" ``` Note that we are using python's interpretation of ruman numerals in a text file as an example for the above operations: In Roman numerals, there are seven characters that are repeated and combined in various ways to represent numbers. - I = 1 - V = 5 - X = 10 - L = 50 - C = 100 - D = 500 - M = 1000 # Groups ## groups() A groups() expression returns a tuple containing all subgroups of the match ```python import re m = re.match(r'(\\w+)@(\\w+)\\.(\\w+)','username@hackerrank.com') m.groups() >>> ('username', 'hackerrank', 'com') ``` ## groupdict() A groupdict() expression returns a dictionary containing all named subgroups of the match. ```python import re m = re.match(r'(?P\\w+)\\.(>P\\w+)' , 'myname@gmail.com') m.groupdict() >>> {'user': 'myname', 'website' : 'gmail', 'extension': 'com'} ``` In the above code we can notice that (\\w+) would mean just a pattern of words, but we can specify a particular key value using the operator ## findall() The expression re.findall() returns non-ovealapping matches of patterns in a string -> as a list of strings ```python import re re.findall(r'\\w', 'http://hackerrank.com/') >>>['h', 't', 't', 'p', 'w', 'w', 'w', 'h', 'a', 'c', 'k', 'e', 'r', 'r', 'a', 'n', 'k', 'c', 'o', 'm'] ``` However, we can replace `\\w` with `\\w+` to extract only words from the string ## finditer() This expression returns a callable iterable object (iterator) over non-overlapping matches in string ```python import re re.finditer(r'\\w', 'http://www.hackerrank.com/') map(lambda x: x.group(),re.finditer(r'\\w','http://www.hackerrank.com/')) >>> ['h', 't', 't', 'p', 'w', 'w', 'w', 'h', 'a', 'c', 'k', 'e', 'r', 'r', 'a', 'n', 'k', 'c', 'o', 'm'] ``` Remember that the map function uses 2 arguments: - a function which it will iterate upon - a list or dictionary of items as input Therefore, we get the output as a list of letters in string # Matching normal digits and re.compile Say we have phone numbers like __800-555-1212__ We can use a modfied form of regex like: ```python >>> phonePattern = re.compile(r'^(\\d{3})−(\\d{3})−(\\d{4})$') >>> phonePattern.search('800−555−1212').groups() ('800', '555', '1212') ``` - Always read regular expressions from left to right. This one matches the beginning of the string, and then (\\d{3}). What's \\d{3}? Well, the {3} means \"match exactly three numeric digits\"; it's a variation on the {n,m} syntax you saw earlier. \\d means \"any numeric digit\" (0 through 9). - Putting it in parentheses means \"match exactly three numeric digits, and then remember them as a group that I can ask for later\". - Then match a literal hyphen. - Then match another group of exactly three digits. - Then another literal hyphen. - Then another group of exactly four digits. - Then match the end of the string. To get access to the groups that the regular expression parser remembered along the way, use the groups() method on the object that the search function returns. It will return a tuple of however many groups were defined in the regular expression. In this case, you defined three groups, one with three digits, one with three digits, and one with four digits. ## Handling different seperators ```python >>> phonePattern = re.compile(r'^(\\d{3})\\D+(\\d{3})\\D+(\\d{4})\\D+(\\d+)$') >>> phonePattern.search('800 555 1212 1234').groups() ('800', '555', '1212', '1234') ``` \\D matches any character except a numeric digit, and + means \"1 or more\". So \\D+ matches one or more characters that are not digits. ## Handling numbers without seperators ```python >>> phonePattern = re.compile(r'^(\\d{3})\\D*(\\d{3})\\D*(\\d{4})\\D*(\\d*)$') >>> phonePattern.search('80055512121234').groups() ('800', '555', '1212', '1234') ``` __Instead of \\D+ between the parts of the phone number, you now match on \\D*. Remember that + means \"1 or more\"? Well, * means \"zero or more\".__ So now you should be able to parse phone numbers even when there is no separator character at all. ## Verbose number handlers Taking the same example of phone numbers and designing a pattern matcher for that: Eg. Phone number: work 1−(800) 555.1212 #1234 ```python phonePattern = re.compile(r''' (\\d{3}) # area code is 3 digits (e.g. '800') \\D* # optional separator is any number of non−digits (\\d{3}) # trunk is 3 digits (e.g. '555') \\D* # optional separator (\\d{4}) # rest of number is 4 digits (e.g. '1212') \\D* # optional separator (\\d*) # extension is optional and can be any number of digits $ # end of string ''', re.VERBOSE) ``` ## Example: find vowels which are 2 chars in length and surrounded by consonants ```python import re v = \"aeiou\" c = \"qwrtypsdfghjklzxcvbnm\" print(*re.findall(\"(?=[%s]([%s]{2,})[%s])\"%(c,v,c),input(), re.I) or [-1], sep=\"\\n\") ``` Note that the print(*..) part is just a cool way of saying: ```python import re v = \"aeiou\" c = \"qwrtypsdfghjklzxcvbnm\" #print(*re.findall(\"(?=[%s]([%s]{2,})[%s])\"%(c,v,c),input(), re.I) or [-1], sep=\"\\n\") pattern = [] pattern = re.findall(\"(?=[%s]([%s]{2,})[%s])\"%(c,v,c),input(), re.I) for i in range(len(pattern)): print(pattern[i]) ``` ## Example: Extracting only words from a string and index all words in a dictionary ```python def get_words(inp_string): string_to_split = str(inp_string) pattern = '[A-Za-z]+' split_list = re.findall(pattern, string_to_split) return split_list def create_dictionary(messages): word_dictionary = {} word_count = 0 for i in range(messages.shape[0]): temp_list = get_words(messages[i]) for j in range(len(temp_list)): if temp_list[j] not in word_dictionary.values(): word_dictionary[word_count] = temp_list[j] word_count += 1 return word_dictionary ``` ",
    "url": "/Regex/",
    "relUrl": "/Regex/"
  },"14": {
    "doc": "Home",
    "title": "Home",
    "content": "# Python Notes {: .fs-9 } [Courseware](https://drive.google.com/file/d/1fDNsbM9I3apBssYNU1ecQZVF7eIbeEzQ/view?usp=sharing){: .btn .fs-5 .mb-4 .mb-md-0 } ",
    "url": "/",
    "relUrl": "/"
  }
}
